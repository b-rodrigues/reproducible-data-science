# Robust Pipelines with Monads

In the previous chapters, you learned functional programming fundamentals and 
how to build reproducible pipelines with `{rixpress}`. Now we'll add another 
layer of robustness: **monads**.

Monads might sound abstract, but they solve concrete problems involving **Logging** (tracing what each step does without cluttering your functions), **Error handling** (letting failures propagate gracefully instead of crashing), and **Composition** (keeping functions composable even when they need to do "extra" work).

By the end of this chapter, you'll know how to integrate `{chronicler}` and 
`talvez` into your pipelines for more robust, observable data workflows.

## The Problem: Decorated Functions Don't Compose

Suppose you want your functions to provide logs. You might rewrite `sqrt()` like 
this:

```{r}
#| eval: false
my_sqrt <- function(x, log = "") {
  list(
    result = sqrt(x),
    log = c(log, paste0("Running sqrt with input ", x))
  )
}

my_log <- function(x, log = "") {
  list(
    result = log(x),
    log = c(log, paste0("Running log with input ", x))
  )
}
```

These functions now return lists with both the result and a log. But there's a 
problem: they don't compose:

```{r}
#| eval: false
# This works:
10 |> sqrt() |> log()

# This fails:
10 |> my_sqrt() |> my_log()
# Error: non-numeric argument to mathematical function
```

`my_log()` expects a number, but `my_sqrt()` returns a list. We've broken 
composition.

## The Solution: Function Factories and Bind

A monad provides two things:

1. **A function factory** that decorates functions so they can provide 
   additional output without rewriting their core logic
2. **A `bind()` function** that makes these decorated functions compose

Here's a simple function factory for logging:

```{r}
#| eval: false
log_it <- function(.f) {
  fstring <- deparse(substitute(.f))
  
  function(..., .log = NULL) {
    list(
      result = .f(...),
      log = c(.log, paste0("Running ", fstring, " with argument ", ...))
    )
  }
}

# Create decorated functions
l_sqrt <- log_it(sqrt)
l_log <- log_it(log)

l_sqrt(10)
#> $result
#> [1] 3.162278
#> $log
#> [1] "Running sqrt with argument 10"
```

Now we need `bind()` to make them compose:

```{r}
#| eval: false
bind <- function(.l, .f) {
  .f(.l$result, .log = .l$log)
}

# Now they compose!
10 |>
  l_sqrt() |>
  bind(l_log)

#> $result
#> [1] 1.151293
#> $log
#> [1] "Running sqrt with argument 10"
#> [2] "Running log with argument 3.16227766016838"
```

This pattern of a function factory plus `bind()` is the essence of a monad.

## A Deeper Look: The Formal Definition

While our function factory approach is practical for R programmers, it's useful
to understand how this relates to the formal definition from Haskell, where
monads originate:

```haskell
class Monad m where
  (>>=)  :: m a -> (a -> m b) -> m b  -- This is bind()
  (>>)   :: m a ->  m b       -> m b  -- We won't need this
  return ::   a               -> m a  -- This wraps a value
```

What this means is that a Monad has three operations:

- `>>=` (called "bind"): exactly what we implemented as our `bind()` function
- `>>` (called "then"): not essential for understanding, so we'll skip it
- `return`: a function that wraps a plain value into a monadic value

Don't be confused by the name `return`—this has nothing to do with R's
`return()` for exiting functions. In monad terminology, `return` (also called
`unit`) takes a value `a` and wraps it into a monadic value `m a`.

While we didn't explicitly implement `return`/`unit`, our function factory
accomplishes the same goal. We can easily derive `unit` from `log_it()`:

```{r}
#| eval: false
unit <- log_it(identity)

unit(10)
#> $result
#> [1] 10
#> $log
#> [1] "Running identity with argument 10"
```

So `return`/`unit` is just the `identity()` function passed through our factory.
In a sense, the function factory is even more fundamental than `return`/`unit`.

## Alternative Perspective: fmap, flatten, and flatmap

You may sometimes read that monads are objects with a `flatmap()` method. This
is another valid perspective. To understand it, we need two helper functions:
`fmap()` and `flatten()`.

**fmap()** applies an *undecorated* function to a monadic value:

```{r}
#| eval: false
fmap <- function(m, f, ...) {
  fstring <- deparse(substitute(f))
  
  list(
    result = f(m$result, ...),
    log = c(m$log, paste0("fmapping ", fstring, " with argument ", m$result))
  )
}

# Create a monadic value using unit()
m <- unit(10)

# Apply an undecorated function
fmap(m, log)
#> $result
#> [1] 2.302585
#> $log
#> [1] "Running identity with argument 10"
#> [2] "fmapping log with argument 10"
```

But what happens if we use `fmap()` with a *decorated* function?

```{r}
#| eval: false
fmap(m, l_log)
#> $result
#> $result$result
#> [1] 2.302585
#> $result$log
#> [1] "Running log with argument 10"
#>
#> $log
#> [1] "Running identity with argument 10"
#> [2] "fmapping l_log with argument 10"
```

We get a nested structure—a monadic value containing another monadic value.
This is where **flatten()** (sometimes called `join()`) comes in:

```{r}
#| eval: false
flatten <- function(m) {
  list(
    result = m$result$result,
    log = c(m$log, m$result$log)
  )
}

flatten(fmap(m, l_log))
#> $result
#> [1] 2.302585
#> $log
#> [1] "Running identity with argument 10"
#> [2] "fmapping l_log with argument 10"
#> [3] "Running log with argument 10"
```

Now here's the key insight: **flatmap is the composition of flatten and fmap**:

```{r}
#| eval: false
# Define a composition operator
`%.%` <- \(f, g)(function(...)(f(g(...))))

# Compose flatten and fmap
# "flatten after fmap"
flatmap <- flatten %.% fmap

# Now we can use flatmap instead of bind:
10 |>
  l_sqrt() |>
  flatmap(l_log)
```

This gives the same result as using `bind()`. I prefer introducing monads via
`bind()` because it comes naturally as a solution to the composition problem.
But in some contexts, thinking in terms of `fmap()` and `flatten()` is more
intuitive, so it's good to know both approaches.

## Lists Are Monads Too

Here's a surprising fact: **lists are monads**. We already have all the
necessary ingredients in base R and `{purrr}`:

- `as.list()` is `return`/`unit`
- `purrr::map()` is `fmap()`
- `purrr::flatten()` is `flatten()`

This means we can derive `flatmap` for lists:

```{r}
#| eval: false
# Compose flatten and map to get flatmap for lists
flatmap_list <- purrr::compose(purrr::flatten, purrr::map)

# Functions that return lists don't compose naturally...
list_sqrt <- \(x)(as.list(sqrt(x)))
list_log <- \(x)(as.list(log(x)))

# But with flatmap_list, they do!
10 |>
  list_sqrt() |>
  flatmap_list(list_log)
#> [[1]]
#> [1] 1.151293
```

This example illustrates that monads are not some exotic concept—they're a
pattern you've likely used without knowing it. Every time you use `purrr` to
chain operations over lists, you're doing monadic programming.

## The chronicler Package


The `{chronicler}` package implements this pattern properly for R. It provides:

- `record()`: A function factory that decorates functions
- `bind_record()`: The bind operation
- Automatic logging of all operations

```{r}
#| eval: false
library(chronicler)

# Decorate functions
r_sqrt <- record(sqrt)
r_exp <- record(exp)
r_mean <- record(mean)

# Compose them
result <- 1:10 |>
  r_sqrt() |>
  bind_record(r_exp) |>
  bind_record(r_mean)

# View the result
result$value
#> [1] 5.187899

# View the log
read_log(result)
#> [1] "Complete log:"
#> [2] "✔ sqrt ran successfully"
#> [3] "✔ exp ran successfully"
#> [4] "✔ mean ran successfully"
```

::: {.callout-tip}
## Getting LLM assistance with `{chronicler}`

If the functional programming patterns in `{chronicler}` feel unfamiliar,
remember that you can use `pkgctx` to generate LLM-ready context. The
`{chronicler}` repository includes a `.pkgctx.yaml` file you can feed to your
LLM. You can also generate your own:

```bash
nix run github:b-rodrigues/pkgctx -- r github:b-rodrigues/chronicler > chronicler.pkgctx.yaml
```

With this context, your LLM can help you refactor your existing functions to be
monadic using `record()` and `bind_record()`.
:::

## The Maybe Monad: Handling Errors

Another common monad is **Maybe**, which handles computations that might fail. 
Instead of crashing, functions return either:

- `Just(value)` if successful
- `Nothing` if something went wrong

The `{chronicler}` package uses this under the hood:

```{r}
#| eval: false
r_sqrt <- record(sqrt)

# This works
r_sqrt(16)
#> ✔ Value: Just
#> [1] 4

# This fails gracefully
r_sqrt("not a number")
#> ✖ Value: Nothing
```

When `Nothing` is passed to a decorated function, it immediately returns 
`Nothing`, the error propagates through the pipeline without crashing.

## Monads in Python: talvez

The same concepts exist in Python. The `talvez` package provides a Maybe monad:

```python
from talvez import maybe, just

@maybe()
def parse_int(s: str) -> int:
    return int(s)

@maybe(ensure=lambda x: x != 0)
def reciprocal(n: int) -> float:
    return 1 / n

# Successful computation
result = (
    parse_int("25")
      .bind(reciprocal)
      .fmap(lambda x: x * 100)
)
print(result)            # Just(4.0)
print(result.get_or(-1)) # 4.0

# Failed computation
bad = (
    parse_int("not a number")
      .bind(reciprocal)
      .fmap(lambda x: x * 100)
)
print(bad)  # Nothing
```

::: {.callout-tip}
## Getting LLM assistance with `talvez`

Just like with `{chronicler}`, you can use `pkgctx` to help your LLM understand
`talvez`. The repository includes a `.pkgctx.yaml` file, or you can generate
one:

```bash
nix run github:b-rodrigues/pkgctx -- python github:b-rodrigues/talvez > talvez.pkgctx.yaml
```

This is particularly useful for learning how to chain monadic operations in
Python correctly.
:::

The key operations are:

- `fmap(fn)`: Apply a pure function to the value inside the monad
- `bind(fn)`: Apply a function that itself returns a monad

## Building Robust Pipelines

The real power of monads becomes apparent when you combine them with pipeline 
orchestration. Consider a typical data pipeline:

```{r}
#| eval: false
# Standard pipeline - fragile
raw_data |>
  basic_cleaning() |>
  recodings() |>
  filter_arrivals() |>
  make_monthly() |>
  make_plot()
```

If `recodings()` fails halfway through, the entire pipeline crashes. You get an 
error message, but no information about what succeeded before the failure.

Now imagine wrapping each function with `record()`:

```{r}
#| eval: false
library(chronicler)

# Robust pipeline with logging
r_basic_cleaning <- record(basic_cleaning)
r_recodings <- record(recodings)
r_filter_arrivals <- record(filter_arrivals)
r_make_monthly <- record(make_monthly)
r_make_plot <- record(make_plot)

result <- raw_data |>
  r_basic_cleaning() |>
  bind_record(r_recodings) |>
  bind_record(r_filter_arrivals) |>
  bind_record(r_make_monthly) |>
  bind_record(r_make_plot)

# Now you get:
# - The result (or Nothing if any step failed)
# - A complete log of which steps ran
# - Exactly where and why it failed
read_log(result)
```

This pattern transforms a fragile script into a robust, observable pipeline.

## Integrating with rixpress

You can combine the power of `{chronicler}` with `{rixpress}` for even more 
robust pipelines. The key insight is that your `user_functions` can use 
`record()` internally:

```{r}
#| eval: false
# functions.R
library(chronicler)

# Create recorded versions of your functions
r_basic_cleaning <- record(function(data) {
  data |>
    select(contains("TIME"), contains("20")) |>
    pivot_longer(cols = contains("20"),
                 names_to = "date",
                 values_to = "passengers")
})

r_recodings <- record(function(data) {
  data |>
    mutate(tra_meas = fct_recode(tra_meas, ...)) |>
    mutate(passengers = as.numeric(passengers))
})

# Export a pipeline function that uses bind_record
process_aviation_data <- function(raw_data) {
  raw_data |>
    r_basic_cleaning() |>
    bind_record(r_recodings)
}
```

Then in your `{rixpress}` pipeline:

```{r}
#| eval: false
library(rixpress)

list(
  rxp_r_file(
    name = avia_raw,
    path = "data/avia.tsv",
    read_function = readr::read_tsv
  ),
  
  rxp_r(
    name = processed_data,
    expr = process_aviation_data(avia_raw),
    user_functions = "functions.R"
  ),
  
  # ... more steps
) |>
  rxp_populate()
```

The `{rixpress}` derivation caches the result while `{chronicler}` provides 
logging and error handling within the step.

## Python Integration with talvez

The same pattern works in Python pipelines:

```python
# functions.py
from talvez import maybe, chain, just

@maybe()
def basic_cleaning(df):
    return df.dropna().reset_index(drop=True)

@maybe()
def recodings(df):
    df['category'] = df['category'].map(category_mapping)
    return df

@maybe()
def filter_arrivals(df):
    return df[df['tra_meas'] == 'Arrivals']

def process_data(raw_df):
    """Returns Just(result) or Nothing with error handling."""
    return chain(
        just(raw_df),
        basic_cleaning,
        recodings,
        filter_arrivals
    )
```

Then in your `{rixpress}` pipeline:

```{r}
#| eval: false
rxp_py(
  name = processed_data,
  expr = "process_data(raw_data)",
  user_functions = "functions.py"
)
```

## The Monadic Laws

For the mathematically curious, monads must satisfy three laws. While you don't
need to know these to *use* monads effectively, understanding them helps you
verify that an implementation is correct.

### First Law: Left Identity

Passing a value to `return`/`unit` and then binding it to a function `f` is the
same as applying `f` directly to the value:

```{r}
#| eval: false
library(chronicler)

a <- as_chronicle(10)  # as_chronicle is chronicler's "return/unit"
r_sqrt <- record(sqrt)

# These should give the same result:
bind_record(a, r_sqrt)$value
#> [1] 3.162278

r_sqrt(10)$value
#> [1] 3.162278
```

### Second Law: Right Identity

Binding a monadic value to `return`/`unit` returns the original value unchanged:

```{r}
#| eval: false
a <- as_chronicle(10)

# Binding to as_chronicle should return the same value:
bind_record(a, as_chronicle)$value
#> [1] 10

a$value
#> [1] 10
```

### Third Law: Associativity

The order of binding operations doesn't matter—applying functions successively
or composing them first gives the same result:

```{r}
#| eval: false
a <- as_chronicle(10)

r_sqrt <- record(sqrt)
r_exp <- record(exp)

# Method 1: Chain binds sequentially
result1 <- bind_record(a, r_sqrt) |>
  bind_record(r_exp)

# Method 2: Compose binds, then apply
composed_fn <- \(x) bind_record(x, r_sqrt) |> bind_record(r_exp)
result2 <- composed_fn(a)

# These should be equal:
result1$value
#> [1] 6.494743

result2$value
#> [1] 6.494743
```

::: {.callout-note}
## A Note on Logs

In `{chronicler}`, the *logs* between these equivalent expressions may differ
slightly (since they record different paths through the code), but the
*values* will always be identical. This is the important property for
computational correctness.
:::

These laws ensure that monadic code behaves predictably—you can refactor bind
chains without changing semantics, and you can trust that composition works as
expected.

## Summary

Monads add a layer of robustness to your pipelines. In this chapter, we covered:

**Core Concepts:**

- A monad provides a **function factory** (to decorate functions) and a
  **`bind()`** function (to compose decorated functions)
- The relationship between `bind()`, `fmap()`, `flatten()`, and `flatmap()`
- The formal Haskell definition with `>>=`, `>>`, and `return`
- Lists as a familiar example of monads (via `purrr::map` and `purrr::flatten`)
- The three **monadic laws** that ensure predictable behaviour

**Practical Tools:**

- **chronicler** (`record()`, `bind_record()`): Logging and error handling for R
- **talvez** (`@maybe()`, `bind()`, `chain()`): Error handling for Python
- **Just/Nothing**: Graceful failure propagation without crashes
- **Integration with rixpress**: Monads within pipeline steps for observability

Combined with `{rixpress}`:

- Nix provides **hermetic, cached execution**
- Monads provide **logging and error handling**
- Together they give you **robust, reproducible, observable pipelines**

This completes our code quality toolkit: environments (Nix), functional code
(FP), testing, pipelines (rixpress), and robustness (monads). In the next
chapter, we'll learn how to distribute our work with Docker, followed by
packaging and continuous integration.
