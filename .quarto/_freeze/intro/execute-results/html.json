{
  "hash": "194f5bf57fcb4463fdeb572f6e4a1949",
  "result": {
    "engine": "knitr",
    "markdown": "# Introduction\n\nThis book will not teach you about machine learning, statistics or\nvisualisation.\n\nThe goal is to teach you a set of tools, practices and project management\ntechniques that should make your projects easier to reproduce, replicate and\nretrace. These tools and techniques can be used right from the start of your\nproject at a minimal cost, such that once you're done with the analysis, you're\nalso done with making the project reproducible. Your projects are going to be\nreproducible simply because they were engineered, from the start, to be\nreproducible.\n\nThere are two main ideas in this book that you need to keep in mind at all times:\n\n- DRY: Don't Repeat Yourself;\n- WIT: Write IT down.\n\nDRY WIT is not only the best type of humour, it is also the best way to write\nreproducible analytical pipelines.\n\n## Who is this book for?\n\nThis book is for anyone that uses raw data to build any type of output based on\nthat raw data. This can be a simple quarterly report for example, in which the\ndata is used for tables and graphs, or a scientific article for a peer reviewed\njournal or even an interactive web application. It doesn't matter, because the\nprocess is, at its core, always very similar:\n\n- Get the data;\n- Clean the data;\n- Write code to analyse the data;\n- Put the results into the final product.\n\nThis book will already assume some familiarity with programming, and in\nparticular the Python programming language. As I've stated in the preface, I'm\nnot a Python expert, but I'm comfortable enough with the language. In any case,\nthis is not a book about programming itself, and bar a short discussion on the\nmerits of the Polars package, I won't be teaching you programming.\n\n## What is the aim of this book?\n\nThe aim of this book is to make the process of analysing data as reliable,\nretraceable, and reproducible as possible, and do this by design. This means\nthat once you're done with the analysis, you're done. You don't want to spend\ntime, which you often don't have anyways, to rewrite or refactor an analysis and\nmake it reproducible after the fact. We both know that this is not going to\nhappen. Once an analysis is done, it's time to go to the next analysis. And if\nyou need to rerun an older analysis (for example, because the data got updated),\nthen you'll simply figure it out at that point, right? That's a problem for\nfuture you, right? Hopefully, future you will remember every quirk of your code\nand know which script to run at which point in the process, which comments are\noutdated and can be safely ignored, what features of the data need to be checked\n(and when they need to be checked), and so on... You better hope future you is a\nmore diligent worker than you!\n\nGoing forward, I'm going to refer to a project that is reproducible as a\n\"reproducible analytical pipeline\", or RAP for short. There are only two ways to\nmake such a RAP; either you are lucky enough to have someone on the team whose\njob is to turn your messy code into a RAP, or you do it yourself. And this\nsecond option is very likely the most common. The issue is, as stated above,\nthat most of us simply don't do it. We are always in the rush to get to the\nresults, and don't think about making the process reproducible. This is because\nwe always think that making the process reproducible takes time and this time is\nbetter spent working on the analysis itself. But this is a misconception, for\ntwo reasons.\n\nThe first reason is that employing the techniques that we are going to discuss\nin this book won't actually take much time. As you will see, they're not really\nthings that you \"add on top of the analysis\", but will be part of the analysis\nitself, and they will also help with managing the project. And some of these\ntechniques will even save you time (especially testing) and headaches.\n\nThe second reason is that an analysis is never, ever, a one-shot. Only the most\nsimple things, like pulling out a number from some data base may be a one-shot.\nAnd even then, chances are that once you provide that number, you'll be asked to\npull out a variation of that number (for example, by disaggregating by one or\nseveral variables). Or maybe you'll get asked for an update to that number in\nsix months. So you will learn very quickly to keep that SQL query in a script\nsomewhere to make sure that you provide a number that is consistent. But what\nabout more complex analyses? Is keeping the script enough? Keeping the script is\nalready a good start of course. The problem is that very often, there is no\nscript, or not a script for each step of the analysis.\n\nI've seen this play out many times in many different organisations. It's that\ntime of the year again, we have to write a report. 10 people are involved, and\njust gathering the data is already complicated. Some get their data from Word\ndocuments attached to emails, some from a website, some from a report from\nanother department that is a PDF... I remember a story that a senior manager at\nmy previous job used to tell us: once, a client put out a call for a project\nthat involved helping them setting up a PDF scraper. They periodically needed\ndata from another department that came in PDFs. The manager asked what was, at\nleast from our perspective, an obvious question: why can't they send you the\nunderlying data from that PDF in a machine readable format? They had never\nthought to ask. So my manager went to that department, and talked to the people\nputting that PDF together. Their answer? \"Well, we could send them the data in\nany format they want, but they've asked us to send the tables in a PDF format\".\n\nSo the first, and probably most important lesson here is: when starting to build\na RAP, make sure that you talk with all the people involved.\n\n## Prerequisites\n\nYou should be comfortable with the Python programming language. This book will\nassume that you have been using Python for some projects already, and want to\nimprove not only your knowledge of the language itself, but also how to\nsuccessfully manage complex projects. Ideally, you should know about packages,\nhow to install them, you should have written some functions already, know about\nloops and have some basic knowledge of data structures like lists. While this is\nnot a book on visualisation, we will be making some graphs using the `plotnine`\npackage, so if you're familiar with that, that's good. If not, no worries,\nvisualisation, data munging or data analysis is not the point of this book.\nChapter 2, *Before we start* should help you gauge how easily you will be able\nto follow this book.\n\nIdeally, you should also not be afraid of not using Graphical User Interfaces\n(GUIs). While you can follow along using an IDE like VS Code, I will not be\nteaching any features from any program with a GUI. This is not to make things\nharder than they should be (quite the contrary actually) but because interacting\ngraphically with a program is simply not reproducible. So our aim is to write\ncode that can be executed non-interactively by a machine. This is because one\nnecessary condition for a workflow to be reproducible and get referred to as a\nRAP, is for the workflow to be able to be executed by a machine, automatically,\nwithout any human intervention. This is the second lesson of building RAPs:\nthere should be no human intervention needed to get the outputs once the RAP is\nstarted. If you achieve this, then your workflow is likely reproducible, or can\nat least be made reproducible much more easily than if it requires some special\nmanipulation by a human somewhere in the loop.\n\n## What actually is reproducibility?\n\nA reproducible project means that this project can be rerun by anyone at 0 (or\nvery minimal) cost. But there are different levels of reproducibility, and I\nwill discuss this in the next section. Let's first discuss some requirements\nthat a project must have to be considered a RAP.\n\n### Using open-source tools to build a RAP is a hard requirement\n\nOpen source is a hard requirement for reproducibility.\n\nNo ifs nor buts. And I'm not only talking about the code you typed for your\nresearch paper/report/analysis. I'm talking about the whole ecosystem that you\nused to type your code and build the workflow.\n\nIs your code open? That's good. Or is it at least available to other people from\nyour organisation, in a way that they could re-execute it if needed? Good.\n\nBut is it code written in a proprietary program, like STATA, SAS or MATLAB? Then\nyour project is not reproducible. It doesn't matter if this code is well\ndocumented and written and available on a version control system (internally to\nyour company or open to the public). This project is just not reproducible. Why?\n\nBecause on a long enough time horizon, there is no way to re-execute your code\nwith the exact same version of the proprietary programming language and on the\nexact same version of the operating system that was used at the time the project\nwas developed. As I'm writing these lines, MATLAB, for example, is at version\nR2022b. And buying an older version may not be simple. I'm sure if you contact\ntheir sales department they might be able to sell you an older version. Maybe\nyou can even simply re-download older versions that you've already bought from their\nwebsite. But maybe it's not that simple. Or maybe they won't offer this option\nanymore in the future, who knows? In any case, if you google \"purchase old\nversion of Matlab\" you will see that many researchers and engineers have this\nneed.\n\n::: {.content-hidden when-format=\"pdf\"}\n<figure>\n    <img src=\"images/matlab_old_version.png\"\n         alt=\"Wanting to run older versions of analytics software is a recurrent need.\"></img>\n    <figcaption>Wanting to run older versions of analytics software is a recurrent need.</figcaption>\n</figure>\n:::\n\n::: {.content-visible when-format=\"pdf\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![Wanting to run older versions of analytics software is a recurrent need.](images/matlab_old_version.png){width=400px}\n:::\n:::\n\n:::\n\nAnd if you're running old code written for version, say, R2008a, there's no\nguarantee that it will produce the exact same results on version 2022b. And\nlet's not even mention the toolboxes (if you're not familiar with MATLAB's\ntoolboxes, they're the equivalent of packages or libraries in other programming\nlanguages). These evolve as well, and there's no guarantee that you can purchase\nolder versions of said toolboxes. And it's likely that newer versions of\ntoolboxes cannot even run on older versions of Matlab.\n\nAnd let me be clear, what I'm describing here with MATLAB could also be said for\nany other proprietary programs still commonly (unfortunately) used in research\nand in statistics (like STATA, SAS or SPSS). And even if some, or even all, of\nthe editors of these proprietary tools provide ways to buy and run older\nversions of their software, my point is that the fact that you have to rely on\nthem for this is a barrier to reproducibility, and there is no guarantee they\nwill provide the option to purchase older versions forever. Also, who guarantees\nthat the editors of these tools will be around forever? Or, and that's more\nlikely, that they will keep offering a program that you install on your machine\ninstead of shifting to a subscription based model?\n\n*For just $199 a month, you can execute your SAS (or whatever) scripts on the\ncloud! Worry about data confidentiality? No worries, data gets encrypted and\nstored safely on our secure servers! Run your analysis from anywhere and don't\nworry about losing your work if your cat knocks over your coffee on your laptop!\nAnd if you purchase the pro licence, for an additional $100 a month, you can\neven execute your code in parallel!*\n\nThink this is science fiction? Google \"SAS cloud\" to see SAS's cloud based\noffering.\n\n### There are hidden dependencies that can hinder the reproducibility of a project\n\nThen there's another problem: let's suppose you've written a nice, thoroughly\ntested and documented workflow, and made it available on Github (and let's even\nassume that the data is available for people to freely download, and that the\npaper is open access). Or, if you're working in the private sector, you did\neverything above as well, the only difference being that the workflow is only\navailable to people inside the company instead of being available freely and\npublicly online.\n\nLet's further assume that you've used R or Python, or any other open source\nprogramming language. Could this study/analysis be said to be reproducible?\nWell, if the analysis ran on a proprietary operating system, then the conclusion\nis: your project is not reproducible.\n\nThis is because the operating system the code runs on can also influence the\noutputs that your pipeline builds. There are some particularities in operating\nsystems that may make certain things work differently. Admittedly, this is in\npractice rarely a problem, but [it does\nhappen](https://github.com/numpy/numpy/issues/9187)^[https://github.com/numpy/numpy/issues/9187],\nespecially if you're working with very high precision floating point arithmetic\nlike you would do in the financial sector for instance.\n\nThankfully, there is no need to change operating systems to deal with this\nissue, and we will learn how to use Docker to safeguard against this problem.\n\n### The requirements of a RAP\n\nSo where does that leave us? Basically, for something to be truly reproducible,\nit has to respect the following bullet points:\n\n- Source code must obviously be available and thoroughly tested and documented (which is why we will be using Git and Github);\n- All the dependencies must be easy to find and install (we are going to deal with this using dependency management tools);\n- To be written with an open source programming language (nocode tools like Excel are by default non-reproducible because they can't be used non-interactively, and which is why we are going to use the Python programming language);\n- The project needs to be run on an open source operating system (thankfully, we can deal with this without having to install and learn to use a new operating system, thanks to Docker);\n- Data and the paper/report need obviously to be accessible as well, if not publicly as is the case for research, then within your company. This means that the concept of \"scripts and/or data available upon request\" belongs in the trash.\n\n\n::: {.content-hidden when-format=\"pdf\"}\n<figure>\n    <img src=\"images/reasonable_request.png\"\n         alt=\"A real sentence from a real paper published in *THE LANCET Regional Health*. How about *make the data available and I won't scratch your car*, how's that for a reasonable request?\"></img>\n    <figcaption>A real sentence from a real paper published in *THE LANCET Regional Health*. How about *make the data available and I won't scratch your car*, how's that for a reasonable request?</figcaption>\n</figure>\n:::\n\n::: {.content-visible when-format=\"pdf\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![A real sentence from a real paper published in *THE LANCET Regional Health*. How about *make the data available and I won't scratch your car*, how's that for a reasonable request?](images/reasonable_request.png){width=1456}\n:::\n:::\n\n:::\n\n## Are there different types of reproducibility?\n\nLet's take one step back: we live in the real world, and in the real world,\nthere are some constraints that are outside of our control. These constraints\ncan make it impossible to build a true RAP, so sometimes we need to settle for\nsomething that might not be a true RAP, but a second or even third best thing.\n\nIn what follows, let's assume this: in the discussion below, code is tested and\ndocumented, so let's only discuss the code running the pipeline itself.\n\nThe *worst* reproducible pipeline would be something that works, but only on\nyour machine. This can be simply due to the fact that you hardcoded paths that\nonly exist on your laptop. Anyone wanting to rerun the pipeline would need to\nchange the paths. This is something that needs to be documented in a README\nwhich we assumed was the case, so there's that. But maybe this pipeline only\nruns on your laptop because the computational environment that you're using is\nhard to reproduce. Maybe you use software, even if it's open source software,\nthat is not easy to install (anyone that tried to install R packages on Linux\nthat depend on the `{rJava}` package know what I'm talking about).\n\nSo a least worse pipeline would be one that could be run more easily on any\nsimilar machine to yours. This could be achieved by not using hardcoded absolute\npaths, and by providing instructions to set up the environment. For example, in\nthe case of Python, this could be as simple as providing a `requirements.txt`\nfile that lists the dependencies of the project, and which could be easily\ninstall using `pip`:\n\n```bash\npip install -r requirements.txt\n```\n\nDoing this ensures that others, or future you, will be able to install\nthe required packages to reproduce a study. However, this is not enough,\nand I will be talking about `pipenv` to do this kind of thing instead of\n`pip`. In the next chapter I'll explain why.\n\n::: {.content-visible when-format=\"pdf\"}\n\\newpage\n:::\n\nYou should also ensure that people run the same analysis on the same version of\nPython that was used to program it. Just installing the right packages is not\nenough. The same code can produce different results on different versions of\nPython, or not even work at all. If you've been using Python for some time, you\ncertainly remember the switch from Python 2 to Python 3... and who knows, the\nswitch to Python 4 might be just as painful!\n\nThe take-away message is that counting on the language itself being stable\nthrough time as a sufficient condition for reproducibility is not enough. We\nhave to set up the code in a way that it actually is reproducible and\nexplicitely deal with versions of the language itself.\n\nSo what does this all mean? This means that reproducibility is on a continuum,\nand depending on the constraints you face your project can be \"not very\nreproducible\" to \"totally reproducible\". Let's consider the following list of\nanything that can influence how reproducible your project truly is:\n\n- Version of the programming language used;\n- Versions of the packages/libraries of said programming language used;\n- Operating System, and its version;\n- Versions of the underlying system libraries (which often go hand in hand with OS version, but not necessarily).\n- And even the hardware architecture that you run all that software stack on.\n\nSo by \"reproducibility is on a continuum\", what I mean is that you could set up\nyour project in a way that none, one, two, three, four or all of the preceding\nitems are taken into consideration when making your project reproducible.\n\nThis is not a novel, or new idea. @peng2011 already discussed this concept\nbut named it the *reproducibility spectrum*. In part 2 of this book, I will\nreintroduce the idea and call it the \"reproducibility iceberg\".\n\n::: {.content-hidden when-format=\"pdf\"}\n<figure>\n    <img src=\"images/repro_spectrum.png\"\n         alt=\"The reproducibility spectrum from Peng's 2011 paper.\"></img>\n    <figcaption>The reproducibility spectrum from Peng's 2011 paper.</figcaption>\n</figure>\n:::\n\n::: {.content-visible when-format=\"pdf\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![The reproducibility spectrum from Peng's 2011 paper.](images/repro_spectrum.png){width=851}\n:::\n:::\n\n:::\n\nLet me just finish this introduction by discussing the last item on the previous\nlist: hardware architecture. You see, Apple has changed the hardware\narchitecture of their computers recently. Their new computers don't use Intel\nbased hardware anymore, but instead Apple's own proprietary architecture (Apple\nSilicon) based on the ARM specification. And what does that mean concretely? It\nmeans that all the binary packages that were built for Intel based Apple\ncomputers cannot run on their new computers (at least not without a\ncompatibility layer). Which means that if you have a recent Apple Silicon\nMacbook and need to install old packages to rerun a project (and we will learn\nhow to do this later in the book), these need to be compiled to work on Apple\nSilicon first. Now I have read about a compatibility layer called Rosetta which\nenables to run binaries compiled for the Intel architecture on the ARM\narchitecture, and maybe this works well with older Python and package binaries\ncompiled for Intel architecture. Maybe, I don't know. But my point is that you\nnever know what might come in the future, and thus needing to be able to compile\nfrom source is important, because compiling from source is what requires the\nleast amount of dependencies that are outside of your control. Relying on\nbinaries is not future-proof (and which is again, another reason why open-source\ntools are a hard requirement for reproducibility).\n\nAnd for you Windows users, don't think that the preceding paragraph does not\nconcern you. I think that it is very likely that Microsoft will push in the\nfuture for OEM manufacturers to build more ARM based computers. There is already\nan ARM version of Windows after all, and it has been around for quite some time,\nand I think that Microsoft will not kill that version any time in the future.\nThis is because ARM is much more energy efficient than other architectures, and\nany manufacturer can build its own ARM cpus by purchasing a license, which can\nbe quite interesting from a business perspective. For example in the case of\nApple Silicon cpus, Apple can now get exactly the cpus they want for their\nmachines and make their software work seamlessly with it (also, further locking\nin their users to their hardware). I doubt that others will pass the chance to\ndo the same.\n\nAlso, something else that might happen is that we might move towards more and\nmore cloud based computing, but I think that this scenario is less likely than\nthe one from before. But who knows. And in that case it is quite likely that the\nactual code will be running on Linux servers that will likely be ARM based\nbecause of energy and licensing costs. Here again, if you want to run your\nhistorical code, you'll have to compile old packages and R versions from source.\n\nOk, so this might seem all incredibly complicated. How on earth are we supposed\nto manage all these risks and balance the immediate need for results with the\nfuture need of rerunning an old project? And what if rerunning this old project\nis not even needed in the future?\n\nThis is where this book will help you. By employing the techniques discussed in\nthis book, not only will it be very easy and quick to set up a project from the\nground up that is truly reproducible, the very fact of building the project this\nway will also ensure that you avoid mistakes and producing results that are\nwrong. It will be easier and faster to iterate and improve your code, to\ncollaborate, and ultimately to trust the results of your pipelines. So even if\nno one will rerun that code ever again, you will still benefit from the best\npractices presented in this book. Let's dive in!\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}